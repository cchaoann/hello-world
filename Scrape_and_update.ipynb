{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scrape and update.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMAFW7Si82Jgc2LtYy/dczT"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaRH2ONugIyE"
      },
      "source": [
        "# Mount google drive at this notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0cxmFbtWUV0",
        "outputId": "f3e51069-458b-4847-8f77-1fd5ec45396e"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fqAXNqIpJLX",
        "outputId": "27ed7590-5f3c-40c1-8e60-8c82f08b3f07"
      },
      "source": [
        "!pip install --upgrade gspread\r\n",
        "!pip install pretty_html_table"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gspread\n",
            "  Downloading https://files.pythonhosted.org/packages/9c/ba/bc8de4f5077bd34bc873bdd67a89cb29c4f181abba8a836d2c6a0a142365/gspread-3.6.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from gspread) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from gspread) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from gspread) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=40.3.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread) (51.0.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.12.0->gspread) (4.2.0)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->gspread) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth>=1.12.0->gspread) (0.4.8)\n",
            "Installing collected packages: gspread\n",
            "  Found existing installation: gspread 3.0.1\n",
            "    Uninstalling gspread-3.0.1:\n",
            "      Successfully uninstalled gspread-3.0.1\n",
            "Successfully installed gspread-3.6.0\n",
            "Collecting pretty_html_table\n",
            "  Downloading https://files.pythonhosted.org/packages/00/64/6c8ebfebfe8c07106faf42ce9b51d3f4f378be10b011a59866df5e11b4d0/pretty_html_table-0.9.dev0.tar.gz\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pretty_html_table) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->pretty_html_table) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas->pretty_html_table) (1.19.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pretty_html_table) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->pretty_html_table) (1.15.0)\n",
            "Building wheels for collected packages: pretty-html-table\n",
            "  Building wheel for pretty-html-table (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty-html-table: filename=pretty_html_table-0.9.dev0-cp36-none-any.whl size=3941 sha256=d3ddcb0f53ec9b04dcb126da5a3ab8d272f959baf58df16381c8e0b1e1a97ca4\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/ba/34/2df2877fbdf547891d44fd85fe8a44d8d3c6a007fb349abd9a\n",
            "Successfully built pretty-html-table\n",
            "Installing collected packages: pretty-html-table\n",
            "Successfully installed pretty-html-table-0.9.dev0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUYnPbBIgRj3"
      },
      "source": [
        "# Google sheet authorization (through service account)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVDtfzghpMby"
      },
      "source": [
        "import gspread\r\n",
        "from oauth2client.service_account import ServiceAccountCredentials\r\n",
        "\r\n",
        "scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\r\n",
        "\r\n",
        "# service key json file\r\n",
        "credentials = ServiceAccountCredentials.from_json_keyfile_name(\r\n",
        "         'gdrive/My Drive/Scraper/scraper-300106-86075dd12529.json', scope) \r\n",
        "\r\n",
        "gc = gspread.authorize(credentials)\r\n",
        "sh = gc.open(\"Drug Safety 0104\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvqiR2DFpNqF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9517b53a-8e30-4aff-b137-fe7755eb47a3"
      },
      "source": [
        "!pip install selenium\r\n",
        "!apt-get update # to update ubuntu to correctly run apt install\r\n",
        "!apt install chromium-chromedriver\r\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\r\n",
        "import sys\r\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\r\n",
        "from selenium import webdriver\r\n",
        "chrome_options = webdriver.ChromeOptions()\r\n",
        "chrome_options.add_argument('--headless')\r\n",
        "chrome_options.add_argument('--no-sandbox')\r\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\r\n",
        "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.6/dist-packages (3.141.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
            "Hit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:5 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:6 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Fetched 252 kB in 2s (145 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (87.0.4280.66-0ubuntu0.18.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: use options instead of chrome_options\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq8sDhxMpNjp"
      },
      "source": [
        "from bs4 import BeautifulSoup\r\n",
        "from pandas import DataFrame\r\n",
        "import datetime\r\n",
        "import time\r\n",
        "import pandas as pd\r\n",
        "from gspread_dataframe import set_with_dataframe\r\n",
        "productlist=sh.worksheet(\"Summary\")\r\n",
        "rows=productlist.get_all_values()\r\n",
        "product_list=DataFrame.from_records(rows[1:],columns = rows[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "umimaqnaKoRo",
        "outputId": "7488638b-991e-49a1-8c0f-4b6de6047c3f"
      },
      "source": [
        "wd.get(\"http://readopac2.ncl.edu.tw/nclJournal/search/search.jsp?search_type=adv&la=ch\")\r\n",
        "search1 = wd.find_element_by_id(\"textfield1\")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NoSuchElementException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-08c902b3e0a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"http://readopac2.ncl.edu.tw/nclJournal/search/search.jsp?search_type=adv&la=ch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msearch1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"textfield1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_id\u001b[0;34m(self, id_)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'foo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \"\"\"\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements_by_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    976\u001b[0m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[1;32m    977\u001b[0m             \u001b[0;34m'using'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             'value': value})['value']\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"textfield1\"]\"}\n  (Session info: headless chrome=87.0.4280.66)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALH9nuGv4JEI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "43a10afb-b34e-48da-b80d-5eceaa3eec62"
      },
      "source": [
        "starttime=time.time()\r\n",
        "uniquelen=[]\r\n",
        "#pi=10\r\n",
        "for pi in range(len(product_list)):\r\n",
        "  name=product_list.iloc[pi]['Generic name']\r\n",
        "  # go to the search webpage\r\n",
        "  wd.get(\"http://readopac2.ncl.edu.tw/nclJournal/search/search.jsp?search_type=adv&la=ch\")\r\n",
        "  r=wd.page_source\r\n",
        "\r\n",
        "  # interact with the page and fill in values\r\n",
        "  search1 = wd.find_element_by_id(\"textfield1\")\r\n",
        "  search2 = wd.find_element_by_id(\"textfield2\")\r\n",
        "  search3 = wd.find_element_by_id(\"textfield3\")\r\n",
        "  dropdowns = wd.find_elements_by_name(\"search_op\")\r\n",
        "  option1 = dropdowns[0]\r\n",
        "  option2 = dropdowns[1]\r\n",
        "  check = wd.find_element_by_xpath(\".//*[@value='一般性']\")\r\n",
        "  num_search = wd.find_element_by_xpath(\".//*[@value='50']\")\r\n",
        "  #print(num_search.is_selected())\r\n",
        "  search1.send_keys(product_list.iloc[pi]['Generic name'])\r\n",
        "  search2.send_keys(product_list.iloc[pi]['English brand name'])\r\n",
        "  search3.send_keys(product_list.iloc[pi]['Chinese brand name'])\r\n",
        "  option1.send_keys(\"OR\")\r\n",
        "  option2.send_keys(\"OR\")\r\n",
        "  check.click()\r\n",
        "  num_search.click()\r\n",
        "  #print(num_search.is_selected())\r\n",
        "  submit=wd.find_element_by_name(\"submit3\")\r\n",
        "  submit.click()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  # s is the result page\r\n",
        "  s=wd.page_source\r\n",
        "\r\n",
        "  # scrape the contents of the result page\r\n",
        "  soup=BeautifulSoup(s)\r\n",
        "\r\n",
        "  # check if the page contains any search result (if not go the next product in the list)\r\n",
        "  pageresult=soup.find('td', attrs={\"class\",\"center\"})\r\n",
        "  if '查無資料' in pageresult.text:\r\n",
        "    df = DataFrame(columns=['id','article','author','journal','date','page','retrieve date','retrieve week #','abstract link','new article or not'])\r\n",
        "    sheet=sh.add_worksheet(name,100,26)\r\n",
        "    set_with_dataframe(sheet,df)\r\n",
        "    print(name+\": \"+str(len(df.index)))\r\n",
        "    continue\r\n",
        "\r\n",
        "  article = soup.select('label > a')\r\n",
        "  if article==[]:\r\n",
        "    totalnum=1\r\n",
        "  else:\r\n",
        "    a=soup.select('div > em')\r\n",
        "    totalnum=int(a[0].text)\r\n",
        "  itera=totalnum//50\r\n",
        "  itera=itera+1\r\n",
        "  towrite=DataFrame(columns=['id','article','author','journal','date','page','retrieve date','retrieve week #','abstract link','new article or not'])\r\n",
        "  dflist=[]\r\n",
        "\r\n",
        "  for it in range(itera):\r\n",
        "    article = soup.select('label > a')\r\n",
        "    article_names = []\r\n",
        "    id=[]\r\n",
        "    if article==[]:\r\n",
        "      art = soup.find(\"div\",attrs={\"class\",\"caption\"})\r\n",
        "      art=art.text\r\n",
        "      art=art.strip()\r\n",
        "      article_names.append(art)\r\n",
        "\r\n",
        "      urlid=wd.current_url\r\n",
        "      start = urlid.find(\"sysId=\")+len(\"sysId=\")\r\n",
        "      end = urlid.find(\"&dtdId=\")\r\n",
        "      urlid=urlid[start:end]\r\n",
        "      urlid=urlid.strip('0')\r\n",
        "      urlid=int(urlid)\r\n",
        "      id.append(urlid)\r\n",
        "\r\n",
        "    else:\r\n",
        "      for ar in article:\r\n",
        "        article_names.append(ar.text)\r\n",
        "      \r\n",
        "      for x in soup.select('label > a'):\r\n",
        "        idd=x['onclick']\r\n",
        "        st = idd.find(\"goDetail('\")+len(\"goDetail('\")\r\n",
        "        en = idd.find(\"','0000\")\r\n",
        "        newid=idd[st:en].strip('0')\r\n",
        "        newid=int(newid)\r\n",
        "        id.append(newid)\r\n",
        "\r\n",
        "\r\n",
        "    publish_info=[]\r\n",
        "    i=0\r\n",
        "    headlink=\"http://readopac3.ncl.edu.tw\"\r\n",
        "\r\n",
        "    for details in soup.find_all('ul', attrs={\"class\",\"publishInfo\"}):\r\n",
        "      publish_info.append([])\r\n",
        "      date_object = datetime.date.today()\r\n",
        "      publish_info[i].append(date_object)\r\n",
        "      weeknum=date_object.isocalendar()[1]\r\n",
        "      publish_info[i].append(weeknum)\r\n",
        "\r\n",
        "      for row in details.find_all('li'):\r\n",
        "        if (row.text=='摘要'):\r\n",
        "          link=row.find('a')\r\n",
        "          linktext=link['href']\r\n",
        "          complete=headlink+linktext\r\n",
        "          publish_info[i].append(complete)\r\n",
        "        elif (row.text):\r\n",
        "          line=row.text\r\n",
        "          if ('民' in line or '頁' in line or (not ':' in line and not line.isdecimal() and not '(' in line and not '下' in line)):\r\n",
        "            publish_info[i].append(line.strip())\r\n",
        "      if (len(publish_info[i])<7):\r\n",
        "        publish_info[i].append(None)\r\n",
        "      uniquelen.append(len(publish_info[i]))\r\n",
        "      i=i+1\r\n",
        "\r\n",
        "    # write to dataframe\r\n",
        "    df = DataFrame(publish_info,columns=['retrieve date','retrieve week #','author','journal','date','page','abstract link'])\r\n",
        "    df['article']=article_names\r\n",
        "    df['id']=id\r\n",
        "    df=df[['id','article','author','journal','date','page','retrieve date','retrieve week #','abstract link',]]\r\n",
        "    df['new article or not']=''\r\n",
        "\r\n",
        "    dflist.append(df)\r\n",
        "\r\n",
        "    # go to the next page (if exists)\r\n",
        "    if it!=itera-1:\r\n",
        "      pn=it+2\r\n",
        "      pagenum=str(pn)\r\n",
        "      xpath=\"//*[text()='\"+pagenum+\"']\"\r\n",
        "      secondpage=wd.find_element_by_xpath(xpath)\r\n",
        "      secondpage.click()\r\n",
        "      k=wd.page_source\r\n",
        "      soup=BeautifulSoup(k)\r\n",
        "\r\n",
        "  towrite=pd.concat(dflist)\r\n",
        "  # Open our new sheet and add some data.\r\n",
        "  sheet=sh.add_worksheet(name,300,26)\r\n",
        "\r\n",
        "  # fill the worksheet with entries in dataframe df\r\n",
        "  set_with_dataframe(sheet,towrite)\r\n",
        "  print(name+\": \"+str(len(towrite.index)))\r\n",
        "sh.del_worksheet(worksheet)\r\n",
        "endtime=time.time()\r\n",
        "print(endtime-starttime)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NoSuchElementException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b5d4176bf517>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;31m# interact with the page and fill in values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0msearch1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"textfield1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0msearch2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"textfield2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0msearch3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"textfield3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_id\u001b[0;34m(self, id_)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element_by_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'foo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \"\"\"\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements_by_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    976\u001b[0m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[1;32m    977\u001b[0m             \u001b[0;34m'using'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             'value': value})['value']\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"[id=\"textfield1\"]\"}\n  (Session info: headless chrome=87.0.4280.66)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUd_pTw07P4s"
      },
      "source": [
        "# get all sheet names in one spread sheet\r\n",
        "sheets=sh.worksheets()\r\n",
        "sheet_names=str(sheets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwjnHbqwYdYz"
      },
      "source": [
        "emaillist=gc.open(\"Drug safety email list\").sheet1\r\n",
        "all=emaillist.get_all_values()\r\n",
        "rec=\"\"\r\n",
        "first=True\r\n",
        "for a in all:\r\n",
        "  if first:\r\n",
        "    rec=rec+a[0]\r\n",
        "    first=False\r\n",
        "  else:\r\n",
        "    rec=rec+\",\"+a[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU0JbXWIc_0j"
      },
      "source": [
        "summary=sh.worksheet(\"Summary\")\r\n",
        "lists=summary.get_all_values()\r\n",
        "summarydf=DataFrame.from_records(lists[1:],columns = lists[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEz9HSJhDRzw"
      },
      "source": [
        "oldcount=[]\r\n",
        "oldcount.append(1)\r\n",
        "oldcount"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZndo3i1sJd4"
      },
      "source": [
        "soup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ_nGDQKt4Fv"
      },
      "source": [
        "summarydf.iloc[pi]['English brand name']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TP2_frXNvvD5"
      },
      "source": [
        "BeautifulSoup(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A9ahKYUpQFQ"
      },
      "source": [
        "'''\r\n",
        "starttime=time.time()\r\n",
        "uniquelen=[]\r\n",
        "flag=0\r\n",
        "emaildf=DataFrame(columns=['product name','id','article','author','journal','date','page','retrieve date','retrive week #','abstract link','new article or not'])\r\n",
        "summary=sh.worksheet(\"Summary\")\r\n",
        "lists=summary.get_all_values()\r\n",
        "summarydf=DataFrame.from_records(lists[1:],columns = lists[0])\r\n",
        "oldcount=[]\r\n",
        "newcount=[]\r\n",
        "numnew=0\r\n",
        "pi=21\r\n",
        "#for pi in range(len(summarydf)):\r\n",
        "name=summarydf.iloc[pi]['Generic name']\r\n",
        "#if summarydf.iloc[pi]['Active'] !=\"Yes\":\r\n",
        "  #continue\r\n",
        "\r\n",
        "if name not in sheet_names:\r\n",
        "  sheet=sh.add_worksheet(name, 300, 26)\r\n",
        "  newwrite=DataFrame(columns=['id','article','author','journal','date','page','retrieve date','retrive week #','abstract link','new article or not'])\r\n",
        "  set_with_dataframe(sheet,newwrite)\r\n",
        "sheet = sh.worksheet(name)\r\n",
        "rows=sheet.get_all_values()\r\n",
        "olddf=DataFrame.from_records(rows[1:],columns = rows[0])\r\n",
        "olddf['new article or not']=''\r\n",
        "\r\n",
        "oldcount.append(len(olddf.index))\r\n",
        "\r\n",
        "values_list = sheet.col_values(1)\r\n",
        "for i in range(1,len(values_list)):\r\n",
        "  values_list[i]=int(values_list[i])\r\n",
        "#id_values=pd.DataFrame(values_list[1:len(values_list)],columns=[values_list[0]])\r\n",
        "\r\n",
        "#name=\"Methoxy polyethylene glycol-epoetin beta\"\r\n",
        "# go to the search webpage\r\n",
        "wd.get(\"http://readopac2.ncl.edu.tw/nclJournal/search/search.jsp?search_type=adv&la=ch\")\r\n",
        "r=wd.page_source\r\n",
        "\r\n",
        "# interact with the page and fill in values\r\n",
        "search1 = wd.find_element_by_id(\"textfield1\")\r\n",
        "search2 = wd.find_element_by_id(\"textfield2\")\r\n",
        "search3 = wd.find_element_by_id(\"textfield3\")\r\n",
        "dropdowns = wd.find_elements_by_name(\"search_op\")\r\n",
        "option1 = dropdowns[0]\r\n",
        "option2 = dropdowns[1]\r\n",
        "check = wd.find_element_by_xpath(\".//*[@value='一般性']\")\r\n",
        "num_search = wd.find_element_by_xpath(\".//*[@value='50']\")\r\n",
        "\r\n",
        "search1.send_keys(name)\r\n",
        "search1.send_keys(summarydf.iloc[pi]['Generic name'])\r\n",
        "search2.send_keys(summarydf.iloc[pi]['English brand name'])\r\n",
        "search3.send_keys(summarydf.iloc[pi]['Chinese brand name'])\r\n",
        "option1.send_keys(\"OR\")\r\n",
        "option2.send_keys(\"OR\")\r\n",
        "check.click()\r\n",
        "num_search.click()\r\n",
        "\r\n",
        "submit=wd.find_element_by_name(\"submit3\")\r\n",
        "submit.click()\r\n",
        "\r\n",
        "# s is the result page\r\n",
        "s=wd.page_source\r\n",
        "\r\n",
        "# scrape the contents of the result page\r\n",
        "soup=BeautifulSoup(s)\r\n",
        "\r\n",
        "# check if the page contains any search result (if not go the next product in the list)\r\n",
        "pageresult=soup.find('td', attrs={\"class\",\"center\"})\r\n",
        "#if '查無資料' in pageresult.text:\r\n",
        "  #newcount.append(0)\r\n",
        "  #continue\r\n",
        "\r\n",
        "article = soup.select('label > a')\r\n",
        "if article==[]:\r\n",
        "  totalnum=1\r\n",
        "else:\r\n",
        "  a=soup.select('div > em')\r\n",
        "  totalnum=int(a[0].text)\r\n",
        "itera=totalnum//50\r\n",
        "itera=itera+1\r\n",
        "towrite=DataFrame(columns=['id','article','author','journal','date','page','retrieve date','retrive week #','abstract link','new article or not'])\r\n",
        "dflist=[]\r\n",
        "\r\n",
        "for it in range(itera):\r\n",
        "  article = soup.select('label > a')\r\n",
        "  article_names = []\r\n",
        "  id=[]\r\n",
        "  if article==[]:\r\n",
        "    art = soup.find(\"div\",attrs={\"class\",\"caption\"})\r\n",
        "    art=art.text\r\n",
        "    art=art.strip()\r\n",
        "    article_names.append(art)\r\n",
        "\r\n",
        "    urlid=wd.current_url\r\n",
        "    start = urlid.find(\"sysId=\")+len(\"sysId=\")\r\n",
        "    end = urlid.find(\"&dtdId=\")\r\n",
        "    urlid=urlid[start:end]\r\n",
        "    urlid=urlid.strip('0')\r\n",
        "    urlid=int(urlid)\r\n",
        "    id.append(urlid)\r\n",
        "\r\n",
        "  else:\r\n",
        "    for ar in article:\r\n",
        "      article_names.append(ar.text)\r\n",
        "    \r\n",
        "    for x in soup.select('label > a'):\r\n",
        "      idd=x['onclick']\r\n",
        "      st = idd.find(\"goDetail('\")+len(\"goDetail('\")\r\n",
        "      en = idd.find(\"','0000\")\r\n",
        "      newid=idd[st:en].strip('0')\r\n",
        "      newid=int(newid)\r\n",
        "      id.append(newid)\r\n",
        "\r\n",
        "\r\n",
        "  publish_info=[]\r\n",
        "  i=0\r\n",
        "  headlink=\"http://readopac3.ncl.edu.tw\"\r\n",
        "  for details in soup.find_all('ul', attrs={\"class\",\"publishInfo\"}):\r\n",
        "    publish_info.append([])\r\n",
        "    date_object = datetime.date.today()\r\n",
        "    publish_info[i].append(date_object)\r\n",
        "    weeknum=date_object.isocalendar()[1]\r\n",
        "    publish_info[i].append(weeknum)\r\n",
        "\r\n",
        "    for row in details.find_all('li'):\r\n",
        "      if (row.text=='摘要'):\r\n",
        "        link=row.find('a')\r\n",
        "        linktext=link['href']\r\n",
        "        complete=headlink+linktext\r\n",
        "        publish_info[i].append(complete)\r\n",
        "      elif (row.text):\r\n",
        "        line=row.text\r\n",
        "        if ('民' in line or '頁' in line or (not ':' in line and not line.isdecimal() and not '(' in line and not '下' in line)):\r\n",
        "          publish_info[i].append(line.strip())\r\n",
        "    if (len(publish_info[i])<7):\r\n",
        "      publish_info[i].append(None)\r\n",
        "    uniquelen.append(len(publish_info[i]))\r\n",
        "    i=i+1\r\n",
        "\r\n",
        "  # write to dataframe\r\n",
        "  df = DataFrame(publish_info,columns=['retrieve date','retrieve week #','author','journal','date','page','abstract link'])\r\n",
        "  df['article']=article_names\r\n",
        "  df['id']=id\r\n",
        "  df=df[['id','article','author','journal','date','page','retrieve date','retrieve week #','abstract link']]\r\n",
        "\r\n",
        "  dflist.append(df)\r\n",
        "\r\n",
        "  # go to the next page (if exists)\r\n",
        "  if it!=itera-1:\r\n",
        "    pn=it+2\r\n",
        "    pagenum=str(pn)\r\n",
        "    xpath=\"//*[text()='\"+pagenum+\"']\"\r\n",
        "    secondpage=wd.find_element_by_xpath(xpath)\r\n",
        "    secondpage.click()\r\n",
        "    k=wd.page_source\r\n",
        "    soup=BeautifulSoup(k)  \r\n",
        "\r\n",
        "towrite=pd.concat(dflist)\r\n",
        "\r\n",
        "idlist=towrite['id']\r\n",
        "towrite=towrite.set_index(\"id\",inplace=False,drop=False)  \r\n",
        "olddf=olddf.set_index(\"id\",inplace=False,drop=False)\r\n",
        "emaildf=emaildf.set_index(\"id\",inplace=False,drop=False)\r\n",
        "\r\n",
        "newentry=DataFrame(columns=['id','article','author','journal','date','page','retrieve date','retrieve week #','abstract link','new article or not'])\r\n",
        "for a in idlist:\r\n",
        "  if a not in values_list:\r\n",
        "    flag=1\r\n",
        "    towrite.loc[a,'new article or not']='new'\r\n",
        "    newf=towrite.loc[a]\r\n",
        "    newentry=newentry.append(newf)\r\n",
        "    #newf=newf[['product name','id','article','author','journal','date','page','retrieve date','retrive week #','abstract link','new article or not']]\r\n",
        "    emaildf=emaildf.append(newf)\r\n",
        "    emaildf.loc[a,'product name']=name\r\n",
        "    numnew=numnew+1\r\n",
        "newentry=newentry.append(olddf)\r\n",
        "\r\n",
        "#  print(name+\": \"+str(len(newentry.index)))\r\n",
        "newcount.append(len(newentry.index))\r\n",
        "newentry=newentry[['id','article','author','journal','date','page','retrieve date','retrieve week #','abstract link','new article or not']]\r\n",
        "\r\n",
        "# fill the worksheet with entries in dataframe df\r\n",
        "set_with_dataframe(sheet,newentry)\r\n",
        "\r\n",
        "\r\n",
        "#sh.del_worksheet(worksheet)\r\n",
        "summarydf['# of search results last week']=oldcount\r\n",
        "summarydf['# of search results this week']=newcount\r\n",
        "set_with_dataframe(summary,summarydf)\r\n",
        "endtime=time.time()\r\n",
        "print(endtime-starttime)\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap68ITenk5hG"
      },
      "source": [
        "sheet = sh.worksheet('Cobimetinib')\r\n",
        "rows=sheet.get_all_values()\r\n",
        "olddf=DataFrame.from_records(rows[1:],columns = rows[0])\r\n",
        "olddf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK2WhElJrdS1"
      },
      "source": [
        "set_with_dataframe(summary,summarydf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyRkklE2l4-7"
      },
      "source": [
        "newentry=DataFrame(columns=['id','article','author','journal','date','page','retrieve date','retrieve week #','abstract link','new article or not'])\r\n",
        "newentry=newentry.append(olddf)\r\n",
        "len(newentry.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHwvbbb3j0-e"
      },
      "source": [
        "from smtplib import SMTP\r\n",
        "from email.mime.text import MIMEText\r\n",
        "from email.mime.multipart import MIMEMultipart\r\n",
        "from pretty_html_table import build_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44qEjBCYjf26"
      },
      "source": [
        "def send_mail(body):\r\n",
        "  message = MIMEMultipart()\r\n",
        "  year = datetime.date.today().isocalendar()[0]\r\n",
        "  message['Subject'] = str(year)+' Week '+str(weeknum)+' update'\r\n",
        "  message['From'] = 'ann.chao@roche.com'\r\n",
        "  recipients = rec\r\n",
        "  message['To'] = recipients\r\n",
        "\r\n",
        "  bodt_text=\"Number of new articles this week: \"+str(numnew)\r\n",
        "  url=\"<p>Click <a href='https://docs.google.com/spreadsheets/d/1hFoe-tSbN1r4qNIXFODXfFllkQpJlV28_ms9ZfqhOII/edit?usp=sharing'>here</a> to view the complete google sheet</p>\"\r\n",
        "  body_content = body\r\n",
        "  message.attach(MIMEText(bodt_text))\r\n",
        "  message.attach(MIMEText(url,\"html\"))\r\n",
        "  message.attach(MIMEText(body_content, \"html\"))\r\n",
        "  msg_body = message.as_string()\r\n",
        "\r\n",
        "  server = SMTP('smtp.gmail.com', 587)\r\n",
        "  server.starttls()\r\n",
        "  server.login(message['From'], 'rongNan325')\r\n",
        "  server.sendmail(message['From'], recipients.split(','), msg_body)\r\n",
        "  server.quit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhQTGMVLefr7"
      },
      "source": [
        "def send_mail_noupdate():\r\n",
        "  message = MIMEMultipart()\r\n",
        "  year = datetime.date.today().isocalendar()[0]\r\n",
        "  message['Subject'] = str(year)+' Week '+str(weeknum)+' update'\r\n",
        "  message['From'] = 'ann.chao@roche.com'\r\n",
        "  recipients = rec\r\n",
        "  message['To'] = recipients\r\n",
        "\r\n",
        "  bodt_text=\"Number of new articles this week: \"+str(numnew)\r\n",
        "  url=\"<p>Click <a href='https://docs.google.com/spreadsheets/d/1hFoe-tSbN1r4qNIXFODXfFllkQpJlV28_ms9ZfqhOII/edit?usp=sharing'>here</a> to view the complete google sheet</p>\"\r\n",
        "  message.attach(MIMEText(bodt_text))\r\n",
        "  message.attach(MIMEText(url,\"html\"))\r\n",
        "  msg_body = message.as_string()\r\n",
        "\r\n",
        "  server = SMTP('smtp.gmail.com', 587)\r\n",
        "  server.starttls()\r\n",
        "  server.login(message['From'], 'rongNan325')\r\n",
        "  server.sendmail(message['From'], recipients.split(','), msg_body)\r\n",
        "  server.quit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAOFtcRJLaSd"
      },
      "source": [
        "flag=0\r\n",
        "weeknum=53\r\n",
        "rec='ann.chao@roche.com,miojasonann@gmail.com'\r\n",
        "numnew=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK-9SA6_kIiU"
      },
      "source": [
        "if flag==1:\r\n",
        "  emaildf=emaildf[['product name','article','author','journal','date','page','abstract link']]\r\n",
        "  mail_message_body = build_table(emaildf,'blue_light')\r\n",
        "  send_mail(mail_message_body)\r\n",
        "else:\r\n",
        "  send_mail_noupdate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmJs1ymIxxed"
      },
      "source": [
        "\"\"\"\r\n",
        "if flag ==1:\r\n",
        "  # Import Python Packages\r\n",
        "  import smtplib\r\n",
        "  # Set Global Variables\r\n",
        "  gmail_user = 'ann.chao@roche.com'\r\n",
        "  gmail_password = ''\r\n",
        "  # Create Email \r\n",
        "  mail_from = gmail_user\r\n",
        "  mail_to = ['ann.chao@roche.com','miojasonann@gmail.com']\r\n",
        "  mail_subject = 'Week '+ weeknum\r\n",
        "  mail_message_body = 'Hello World!'\r\n",
        "\r\n",
        "  mail_message = '''\\\r\n",
        "  From: %s\r\n",
        "  To: %s\r\n",
        "  Subject: %s\r\n",
        "  %s\r\n",
        "  ''' % (mail_from, mail_to, mail_subject, mail_message_body)\r\n",
        "  # Sent Email\r\n",
        "  server = smtplib.SMTP_SSL('smtp.gmail.com', 465)\r\n",
        "  server.login(gmail_user, gmail_password)\r\n",
        "  server.sendmail(mail_from, mail_to, mail_message)\r\n",
        "  server.close()\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6424KMi6FEkK"
      },
      "source": [
        "import datetime\r\n",
        "datetime.date.today().isocalendar()[1]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}